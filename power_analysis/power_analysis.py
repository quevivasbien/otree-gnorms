# -*- coding: utf-8 -*-
"""power_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lji-QgUB6cLUBJnzmmGPNgRJTHmMnxHO
"""

import numpy as np
import pandas as pd
import statsmodels.api as sm

import multiprocessing

import warnings

warnings.filterwarnings("ignore")


# define possible values of performance and self-promotion
promote_options = list(range(7))
perform_options = list(range(20 + 1))
perform_eval_options = list(range(10 + 1))

# female_p is proba that participant is female
female_p = 0.5

# performance cdfs come from figure 1a in exley-kessler
# values run from -1 to 20
perform_cdf_male = [
    0,
    0,
    0.01,
    0.03,
    0.09,
    0.15,
    0.21,
    0.3,
    0.35,
    0.42,
    0.49,
    0.58,
    0.65,
    0.72,
    0.82,
    0.9,
    0.95,
    0.98,
    0.99,
    1.0,
    1.0,
    1.0,
]
perform_cdf_female = [
    0,
    0,
    0.01,
    0.02,
    0.07,
    0.09,
    0.14,
    0.19,
    0.28,
    0.34,
    0.41,
    0.5,
    0.61,
    0.72,
    0.83,
    0.92,
    0.96,
    0.99,
    0.99,
    1.0,
    1.0,
    1.0,
]

# pdf values run from 0 to 20
perform_pdf_male = np.diff(perform_cdf_male)
perform_pdf_female = np.diff(perform_cdf_female)

# constants for number of evaluations done by each employer
answers_per_employer = 10

default_n_applicants = 400


# ~~~Define helper functions for sampling performance~~~


def sample_10_(k):
    """Samples number correct out of 10 randomly-selected questions,
    from 20 total, assuming k out of 20 correct"""
    correct = np.zeros(20, dtype=int)
    correct[:k] = 1
    return np.random.choice(correct, size=10, replace=False).sum()


sample_10 = np.vectorize(sample_10_, otypes=[int])


def sample_perform(n, pdf):
    """Samples from performance options,
    then splits into evaluation and job subsets of ten each"""
    perform_20 = np.random.choice(perform_options, size=n, replace=True, p=pdf)
    perform_eval = sample_10(perform_20)
    return np.stack((perform_eval, perform_20), axis=1)


def get_perform(n, app_female):
    n_female = app_female.sum()
    app_perform = np.empty((n, 2), dtype=int)
    app_perform[app_female, :] = sample_perform(n_female, perform_pdf_female)
    app_perform[~app_female, :] = sample_perform(n - n_female, perform_pdf_male)
    return app_perform


default_emp_var = 20
default_emp_corr = 0.2

# this dictionary stores covariance matrices, so we don't have to regenerate them all the time
covmats = {}


def gen_errors(var, corr, n_employers):
    """generate clustered errors"""
    # create covariance matrix, or draw from covmats if it's pre-generated
    covmat = covmats.get((var, corr))
    if covmat is None:
        covmat = var * corr * np.ones(
            (answers_per_employer, answers_per_employer)
        ) + var * np.diag(np.ones(answers_per_employer))
        covmats[(var, corr)] = covmat
    # draw clustered errors
    emp_errors = np.array(
        [
            np.random.multivariate_normal(
                mean=np.zeros(answers_per_employer), cov=covmat
            )
            for _ in range(n_employers)
        ]
    )
    return emp_errors


# Define base class used to construct simulated data


class PowerTest:
    def __init__(
        self,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.2,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        self.employer_var = employer_var
        self.employer_corr = employer_corr
        self.promote0 = promote0
        self.promote1 = promote1
        self.promote2 = promote2
        self.verbose = verbose
        self.min_n = min_n
        self.measure2 = measure2

    def create_errors(self, repeat, final_length, n_employers):
        """Generates employer ids and errors for employer wage bids"""
        errors = np.stack(
            [
                np.concatenate(
                    gen_errors(self.employer_var, self.employer_corr, n_employers)
                )[:final_length]
                for _ in range(repeat)
            ],
            axis=0,
        )
        emp_ids = np.array(
            sum(([i] * answers_per_employer for i in range(n_employers)), [])
        )[:final_length]
        return emp_ids, errors

    # Define function for sampling value of self-promotion, performance, & gender
    def gen_data(
        self,
        repeat,
        n_applicants=default_n_applicants,
        n_employers=None,
        filter_treatment=None,
        filter_percentile=None,
    ):
        """Create simulated data

        What needs to happen here:
        1. Generate applicant data

        2. {If we're testing a hypothesis on employer bids:}
        len of each rep needs to be n_employers * answers_per_employer
        -> replicate applicant data (n_employers * answer_per_employer) / n_applicants times
        create errors clustered in blocks of size answers_per_employer
        """
        # sample applicant genders
        treatment = np.random.choice(
            range(3), size=(repeat, n_applicants), replace=True
        )
        app_female = np.random.binomial(
            1, size=(repeat, n_applicants), p=female_p
        ).astype(bool)
        # sample applicant performance and self-promotion
        app_perform = np.stack(
            [get_perform(n_applicants, appfem) for appfem in app_female]
        )
        app_promote = (
            (
                app_female
                * (
                    self.promote0 * (treatment == 0)
                    + self.promote1 * (treatment == 1)
                    + self.promote2 * (treatment == 2)
                )
                + 0.6 * app_perform[:, :, 0]
                + np.random.normal(size=(repeat, n_applicants))
            )
            * (20 if self.measure2 else 1)
        ).astype(int)
        app_promote[app_promote < 0] = 0
        if self.measure2:
            app_promote[app_promote > 100] = 100
        else:
            app_promote[app_promote > 5] = 5
        if n_employers is not None:
            # duplicate applicant data, if needed
            final_length = n_employers * answers_per_employer
            evals_per_app = np.ceil(final_length / n_applicants).astype(int)
            treatment = np.tile(treatment, (1, evals_per_app))[:, :final_length]
            app_female = np.tile(app_female, (1, evals_per_app))[:, :final_length]
            app_perform = np.tile(app_perform, (1, evals_per_app, 1))[
                :, :final_length, :
            ]
            app_promote = np.tile(app_promote, (1, evals_per_app))[:, :final_length]

            # generate employer ids and error terms
            emp_id, error = self.create_errors(repeat, final_length, n_employers)
            d = [
                pd.DataFrame(
                    {
                        "treatment": treatment[i, :],
                        "app_female": app_female[i, :],
                        "app_perform": app_perform[i, :, 0],
                        "app_perform_all": app_perform[i, :, 1],
                        "app_promote": app_promote[i, :],
                        "emp_id": emp_id,
                        "error": error[i, :],
                    }
                )
                for i in range(repeat)
            ]
        else:
            d = [
                pd.DataFrame(
                    {
                        "treatment": treatment[i, :],
                        "app_female": app_female[i, :],
                        "app_perform": app_perform[i, :, 0],
                        "app_perform_all": app_perform[i, :, 1],
                        "app_promote": app_promote[i, :],
                    }
                )
                for i in range(repeat)
            ]
        # do needed filtering, if any
        if filter_percentile is not None:
            for i in range(repeat):
                percentile = np.percentile(d[i]["app_perform_all"], filter_percentile)
                d[i] = d[i][d[i]["app_perform_all"] > percentile]
        if filter_treatment is not None:
            for i in range(repeat):
                d[i] = d[i][d[i]["treatment"] == filter_treatment]
        return d

    def est_power(self, repeat, n):
        raise NotImplementedError

    def test(
        self,
        repeat=400,
        n=100,
        last_n=0,
        refine_repeat=None,
        target_power=0.8,
        alpha=0.05,
        maxiter=20,
    ):
        """Base function for actually carrying out hypothesis test"""
        for _ in range(maxiter):
            if n <= self.min_n:
                print(
                    f"reached minimum allowed n ({self.min_n}) on {self.__class__.__name__}"
                )
                return self.min_n
            est_power = self.est_power(repeat, n, alpha)
            if self.verbose:
                print(n, est_power)
            # choose next sample size
            n, last_n = int((n * (1 + target_power - est_power))), n
            if n == last_n:
                # fine-tune
                if refine_repeat is not None and repeat < refine_repeat:
                    return self.test(
                        refine_repeat, n, 0, refine_repeat, target_power, alpha
                    )
                else:
                    return n if est_power > target_power else n + 1
        print(f"maximum iterations ({maxiter}) reached on {self.__class__.__name__}")
        return n


class Hypothesis1(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n_employers=n, filter_treatment=0)
        oks = []
        # calculate p-values for each
        for d in data:
            wagebid = self.beta0 + self.beta1 * d["app_promote"] + d["error"]
            X = sm.add_constant(d["app_promote"])
            try:
                fitted = sm.OLS(wagebid, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = fitted.pvalues[1] < alpha
            except (ValueError, IndexError) as e:
                if self.verbose:
                    print(f"received error {e} in Hyp1; trying again...")
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        # estimate power
        return np.mean(oks)


# Hypothesis1(0, 5, verbose=True).test()


class Hypothesis2(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n_employers=n, filter_treatment=1)
        oks = []
        for d in data:
            app_promoteXapp_female = d["app_promote"] * d["app_female"]
            wagebid = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * d["app_female"]
                + self.beta3 * app_promoteXapp_female
                + d["error"]
            )
            X = sm.add_constant(
                np.stack(
                    (d["app_promote"], d["app_female"], app_promoteXapp_female), axis=1
                )
            )
            try:
                fitted = sm.OLS(wagebid, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = all(fitted.pvalues[i] < alpha for i in (1, 3))
            except (ValueError, IndexError) as e:
                if self.verbose:
                    print(f"received error {e} in Hyp2; trying again...")
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)


# Hypothesis2(0, 10, 0, -3, verbose=True).test()


class Hypothesis3(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        perform_step,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3
        self.perform_step = perform_step

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n_employers=n, filter_treatment=2)
        oks = []
        for d in data:
            femaleXselfpromotion = d["app_female"] * d["app_promote"]
            wagebid = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * d["app_female"]
                + self.beta3 * femaleXselfpromotion
                + self.perform_step * d["app_perform"]
                + d["error"]
            )
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            X = sm.add_constant(
                np.concatenate(
                    (
                        np.stack(
                            (d["app_promote"], d["app_female"], femaleXselfpromotion),
                            axis=1,
                        ),
                        perform_dummies,
                    ),
                    axis=1,
                )
            )
            try:
                fitted = sm.OLS(wagebid, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = all(fitted.pvalues[i] < alpha for i in (1, 3))
            except (IndexError, ValueError) as e:
                if self.verbose:
                    print(f"received error {e} in Hyp3; trying again...")
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)


# Hypothesis3(0, 10, 0, -2, 5, verbose=True).test()


class Hypothesis4(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n_applicants=n, n_employers=n, filter_treatment=0)
        oks = []
        for d in data:
            guesserisfemale = np.random.binomial(1, size=len(d), p=0.5)
            guesserisfemaleXselfpromotion = guesserisfemale * d["app_promote"]
            wageguess = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * guesserisfemale
                + self.beta3 * guesserisfemaleXselfpromotion
                + d["error"]
            )
            # calculate p-values for each
            X = sm.add_constant(
                np.stack(
                    (d["app_promote"], guesserisfemale, guesserisfemaleXselfpromotion),
                    axis=1,
                )
            )
            try:
                fitted = sm.OLS(wageguess, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = fitted.pvalues[1] < alpha and fitted.pvalues[3] < alpha
            except (IndexError, ValueError) as e:
                print(f'received error ""{e}"" in Hyp4; trying again...')
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)


# Hypothesis4(0, 10, 0, -3, verbose=True).test()


class Hypothesis5(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=40,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(
            repeat, n_applicants=n // 2, n_employers=n // 2, filter_treatment=1
        )
        oks = []
        for d in data:
            selfpromotionXfemale = d["app_promote"] * d["app_female"]
            wageguess = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * d["app_female"]
                + self.beta3 * selfpromotionXfemale
                + d["error"]
            )
            X = sm.add_constant(
                np.stack(
                    (d["app_promote"], d["app_female"], selfpromotionXfemale), axis=1
                )
            )
            try:
                fitted = sm.OLS(wageguess, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = fitted.pvalues[1] < alpha and fitted.pvalues[3] < alpha
            except (IndexError, ValueError) as e:
                print(f'received error ""{e}"" in Hyp5; trying again...')
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)


# Hypothesis5(0, 10, 0, -3, verbose=True).test()


class Hypothesis6(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        perform_step,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=40,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3
        self.perform_step = perform_step

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(
            repeat, n_applicants=n // 2, n_employers=n // 2, filter_treatment=2
        )
        oks = []
        for d in data:
            selfpromotionXfemale = d["app_promote"] * d["app_female"]
            wageguess = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * d["app_female"]
                + self.beta3 * selfpromotionXfemale
                + self.perform_step * d["app_perform"]
                + d["error"]
            )
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            X = sm.add_constant(
                np.concatenate(
                    (
                        np.stack(
                            (d["app_promote"], d["app_female"], selfpromotionXfemale),
                            axis=1,
                        ),
                        perform_dummies,
                    ),
                    axis=1,
                )
            )
            try:
                fitted = sm.OLS(wageguess, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = fitted.pvalues[1] < alpha and fitted.pvalues[3] < alpha
            except (IndexError, ValueError) as e:
                print(f'received error ""{e}"" in Hyp6; trying again...')
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)


# Hypothesis6(0, 5, 0, -2, 5, verbose=True).test()


class Hypothesis7(PowerTest):
    def __init__(
        self,
        beta0,
        beta1,
        beta2,
        beta3,
        perform_step,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=40,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )
        self.beta0 = beta0
        self.beta1 = beta1
        self.beta2 = beta2
        self.beta3 = beta3
        self.perform_step = perform_step

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(
            repeat,
            n_applicants=n // 2,
            n_employers=n // 2,
            filter_treatment=2,
            filter_percentile=75,
        )
        oks = []
        for d in data:
            selfpromotionXfemale = d["app_promote"] * d["app_female"]
            wageguess = (
                self.beta0
                + self.beta1 * d["app_promote"]
                + self.beta2 * d["app_female"]
                + self.beta3 * selfpromotionXfemale
                + self.perform_step * d["app_perform"]
                + d["error"]
            )
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            try:
                X = sm.add_constant(
                    np.concatenate(
                        (
                            np.stack(
                                (
                                    d["app_promote"],
                                    d["app_female"],
                                    selfpromotionXfemale,
                                ),
                                axis=1,
                            ),
                            perform_dummies,
                        ),
                        axis=1,
                    )
                )
            except ValueError as e:
                print(f'received error "{e}" in Hyp7; trying again...')
                return self.est_power(repeat, n, alpha)
            try:
                fitted = sm.OLS(wageguess, X).fit(
                    cov_type="cluster", cov_kwds={"groups": d["emp_id"]}
                )
                ok = fitted.pvalues[1] < alpha and fitted.pvalues[3] < alpha
            except (IndexError, ValueError) as e:
                print(f'received error "{e}" in Hyp7; trying again...')
                return self.est_power(repeat, n, alpha)
            oks.append(ok)
        return np.mean(oks)

    def test(
        self,
        repeat=400,
        n=400,
        last_n=0,
        refine_repeat=None,
        target_power=0.8,
        alpha=0.05,
        maxiter=20,
    ):
        """Need to overwrite starting guess for n here since 100 is too low."""
        return super().test(
            repeat, n, last_n, refine_repeat, target_power, alpha, maxiter
        )


# Hypothesis7(0, 5, 0, -2, 5, verbose=True).test()


class Hypothesis8(PowerTest):
    def __init__(
        self,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n)
        # no need to create dependent variable since it's part of gen_data()
        pvals = []
        # calculate p-values for each
        for d in data:
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            X = sm.add_constant(
                np.concatenate(
                    (d["app_female"].to_numpy().reshape(-1, 1), perform_dummies), axis=1
                )
            )
            pval = sm.OLS(d["app_promote"], X).fit(cov_type="HC3").pvalues[1]
            pvals.append(pval)
        return sum(1 for p in pvals if p < alpha) / len(pvals)


# Hypothesis8(verbose=True).test()


class Hypothesis9(PowerTest):
    def __init__(
        self,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n)
        oks = []
        for d in data:
            # filter out treatment 3
            d = d[d["treatment"] != 2]
            femt1 = d["app_female"] & (d["treatment"] == 1)
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            X = sm.add_constant(
                np.concatenate(
                    (
                        np.stack(
                            (d["app_female"], (d["treatment"] == 1), femt1), axis=1
                        ),
                        perform_dummies,
                    ),
                    axis=1,
                )
            )
            fitted = sm.OLS(d["app_promote"], X).fit(cov_type="HC3")
            ok = fitted.pvalues[3] < alpha
            oks.append(ok)
        return np.mean(oks)


# Hypothesis9(verbose=True).test()


class Hypothesis10(PowerTest):
    def __init__(
        self,
        employer_var=default_emp_var,
        employer_corr=default_emp_corr,
        promote0=-0.1,
        promote1=-1.0,
        promote2=-0.5,
        verbose=False,
        min_n=20,
        measure2=False,
    ):
        super().__init__(
            employer_var,
            employer_corr,
            promote0,
            promote1,
            promote2,
            verbose,
            min_n,
            measure2,
        )

    def est_power(self, repeat, n, alpha=0.05):
        data = self.gen_data(repeat, n)
        oks = []
        for d in data:
            # filter out treatment 1
            d = d[d["treatment"] != 0]
            femt2 = d["app_female"] & (d["treatment"] == 2)
            perform_dummies = pd.get_dummies(d["app_perform"]).to_numpy()[:, :-1]
            X = sm.add_constant(
                np.concatenate(
                    (
                        np.stack(
                            (d["app_female"], (d["treatment"] == 2), femt2), axis=1
                        ),
                        perform_dummies,
                    ),
                    axis=1,
                )
            )
            fitted = sm.OLS(d["app_promote"], X).fit(cov_type="HC3")
            ok = fitted.pvalues[3] < alpha
            oks.append(ok)
        return np.mean(oks)


# Hypothesis10(verbose=True).test()

# set default assumptions for wage coeffs
default_wage_coeffs = [
    [0, 5],
    [0, 10, 0, -3],
    [0, 10, 0, -2, 5],
    [0, 10, 0, -3],
    [0, 10, 0, -3],
    [0, 5, 0, -2, 5],
    [0, 5, 0, -2, 5],
]

# assumption for smaller effect sizes
reduced_wage_coeffs = [[x / 2 for x in y] for y in default_wage_coeffs]

# assumptions for measure 2
measure2_wage_coeffs = [
    [0, 0.25],
    [0, 0.5, 0, -0.15],
    [0, 0.5, 0, -0.1, 5],
    [0, 0.5, 0, -0.15],
    [0, 0.5, 0, -0.15],
    [0, 0.25, 0, -0.1, 5],
    [0, 0.25, 0, -0.1, 5],
]

measure2_reduced_coeffs = [[x / 2 for x in y] for y in measure2_wage_coeffs]


def run_all(
    emp_var=None,
    emp_corr=None,
    promote0=None,
    promote1=None,
    promote2=None,
    w=None,
    measure2=None,
):
    if emp_var is None:
        emp_var = default_emp_var
    if emp_corr is None:
        emp_corr = default_emp_corr
    if promote0 is None:
        promote0 = -0.1
    if promote1 is None:
        promote1 = -1.0
    if promote2 is None:
        promote2 = -0.5
    if w is None:
        w = default_wage_coeffs
    if measure2 is None:
        measure2 = False
    return [
        Hypothesis1(
            w[0][0],
            w[0][1],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis2(
            w[1][0],
            w[1][1],
            w[1][2],
            w[1][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis3(
            w[2][0],
            w[2][1],
            w[2][2],
            w[2][3],
            w[2][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis4(
            w[3][0],
            w[3][1],
            w[3][2],
            w[3][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis5(
            w[4][0],
            w[4][1],
            w[4][2],
            w[4][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis6(
            w[5][0],
            w[5][1],
            w[5][2],
            w[5][3],
            w[5][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis7(
            w[6][0],
            w[6][1],
            w[6][2],
            w[6][3],
            w[6][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).test(),
        Hypothesis8(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).test(),
        Hypothesis9(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).test(),
        Hypothesis10(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).test(),
    ]


def create_table(sizes, titles):
    """sizes should be 8 x n numpy array, each column of sizes is output of run_all
    titles should be list of len n"""
    sizes = sizes.astype(str)
    out = (
        "\\begin{tabular}{c|" + "c" * sizes.shape[1] + "}\n"
        "Hypothesis & "
        + " & ".join(titles)
        + " \\\\\n\\hline\n"
        + " \\\\\n".join(
            f"{i} & " + " & ".join(s) for i, s in zip(range(1, 10 + 1), sizes)
        )
        + " \\\\\n\\end{tabular}"
    )
    return out


def pool_func(args):
    promote1, promote2, measure2, w = args
    return run_all(promote1=promote1, promote2=promote2, measure2=measure2, w=w)


args = [
    (None, None, None, None),
    (-0.5, -0.3, None, reduced_wage_coeffs),
    (None, None, True, measure2_wage_coeffs),
    (-0.5, -0.3, True, measure2_reduced_coeffs),
]


with multiprocessing.Pool(processes=4) as pool:
    run_A, run_B, run_C, run_D = tuple(pool.map(pool_func, args))


out = create_table(
    np.stack((run_A, run_B, run_C, run_D), axis=1), ["(A)", "(B)", "(C)", "(D)"]
)
print(out)


# get power calculations for each hypothesis, with sample size given
def run_all_single_n(
    n_applicants=350,
    n_employers=200,
    repeat=1000,
    emp_var=None,
    emp_corr=None,
    promote0=None,
    promote1=None,
    promote2=None,
    w=None,
    measure2=None,
):
    if emp_var is None:
        emp_var = default_emp_var
    if emp_corr is None:
        emp_corr = default_emp_corr
    if promote0 is None:
        promote0 = -0.1
    if promote1 is None:
        promote1 = -1.0
    if promote2 is None:
        promote2 = -0.5
    if w is None:
        w = default_wage_coeffs
    if measure2 is None:
        measure2 = False
    return [
        Hypothesis1(
            w[0][0],
            w[0][1],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_employers),
        Hypothesis2(
            w[1][0],
            w[1][1],
            w[1][2],
            w[1][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_employers),
        Hypothesis3(
            w[2][0],
            w[2][1],
            w[2][2],
            w[2][3],
            w[2][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_employers),
        Hypothesis4(
            w[3][0],
            w[3][1],
            w[3][2],
            w[3][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_applicants),
        Hypothesis5(
            w[4][0],
            w[4][1],
            w[4][2],
            w[4][3],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_applicants),
        Hypothesis6(
            w[5][0],
            w[5][1],
            w[5][2],
            w[5][3],
            w[5][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_applicants),
        Hypothesis7(
            w[6][0],
            w[6][1],
            w[6][2],
            w[6][3],
            w[6][4],
            emp_var,
            emp_corr,
            promote0,
            promote1,
            promote2,
            measure2=measure2,
        ).est_power(repeat, n_applicants),
        Hypothesis8(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).est_power(repeat, n_applicants),
        Hypothesis9(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).est_power(repeat, n_applicants),
        Hypothesis10(
            emp_var, emp_corr, promote0, promote1, promote2, measure2=measure2
        ).est_power(repeat, n_applicants),
    ]


def pool_func_single_n(args):
    promote1, promote2, measure2, w = args
    return run_all_single_n(
        promote1=promote1, promote2=promote2, measure2=measure2, w=w
    )


with multiprocessing.Pool(processes=4) as pool:
    run_A_single_n, run_B_single_n, run_C_single_n, run_D_single_n = tuple(
        pool.map(pool_func_single_n, args)
    )


out_single_n = create_table(
    np.stack((run_A_single_n, run_B_single_n, run_C_single_n, run_D_single_n), axis=1),
    ["(A)", "(B)", "(C)", "(D)"],
)
print(out_single_n)
